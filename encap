#!/usr/bin/env python

import os
import glob

import encap_lib.encap_settings as settings
from encap_lib.machines import LocalMachine
from encap_lib.encap_lib import get_machine, filename_and_file_extension, get_interpreter_from_file_extension, extract_folder_name
from encap_lib.encap_lib import record_process, remove_process_from_database
from encap_lib import slurm
from encap_lib.git_tracker import get_commit_hashes

def tail_pull(machine, run_folder_name, pid=None):
    if pid is not None:
        machine.run_code(f"tail -f -n +1 --pid={pid} -f {run_folder_name}/log", verbose=True, output=True)
        machine.run_code(f"rm {run_folder_name}/pid")
    else:
        # Runs the tail command until it sees the special character
        machine.run_code(f"""#!/bin/bash
while IFS= read -r LOGLINE || [[ -n "$LOGLINE" ]]; do
    [[ "${{LOGLINE}}" == "{chr(4)}" ]] && exit 0
    printf '%s\\n' "$LOGLINE"
done < <(tail -f {run_folder_name}/log)
""", verbose=True, output=True)
    
    machine.pull(run_folder_name, run_folder_name, directory=True)

# Bash code to run the file and save outputs in log, save PID in the file pid.
def run(machine, file_extension, args, run_folder_name, target_file, target_file_path, interprter_args="", number_of_instances=1):
    machine.push(target_file_path, target_file_path, directory=False, verbose=True)
    
    interpreter = get_interpreter_from_file_extension(file_extension)

    if isinstance(number_of_instances, int):
        iterator = range(number_of_instances)
    else:
        iterator = number_of_instances

    pids = []
    for i in iterator:

        if i == 0:
            log = "log"
        else:
            log = f"log_{i}"
        
        print_instance = ""
        if len(iterator) > 1:
            print_instance = f"echo 'Instance {i}' &>> {log}"
        
        code = f'''
        set -e # Exit on error
        
        cd {run_folder_name}
        export ENCAP_PROCID={i}
        date &> {log}
        echo "host: $(hostname)" &>> {log}
        {print_instance}
        echo "{target_file_path} {args}  \n" &>> {log}
        # Tee avoids buffering
        setsid nohup bash -c "time ({interpreter} {interprter_args} {target_file} {args}) 2>&1 | tee -a /dev/null" &>> {log} &!
        PID=$!
        echo $PID 
        '''

        if i == 0:
            code += f"""
        
        echo "$PID" > pid"""
            pid = machine.run_code(code, output=True)[0]
            print('PID ' + pid)
        else:
            pid = machine.run_code(code, output=True)[0]
        
        pids.append(pid)

    return pids[0]

def run_slurm(machine, file_extension, target, args, run_folder_name, target_file, target_file_path, slurm_settings, interpreter_args="", name=None):
    machine.push(target_file_path, target_file_path, directory=False, verbose=True)

    # Delete previous log file and create a new one
    machine.run_code(f"""rm {run_folder_name}/pid -f
    rm {run_folder_name}/slurm_files/log* -f
    touch {run_folder_name}/log
    mkdir -p {run_folder_name}/slurm_files
    """)
    if not ("i" in slurm_settings):
        slurm_settings["i"] = 1

    if isinstance(slurm_settings["i"], int):
        iterator = range(slurm_settings["i"])
    else:
        iterator = slurm_settings["i"]

    # Create the slurm script for all slurm instances
    for i in iterator:
        if i == 0:
            slurm_instance_text = ""
        else:
            slurm_instance_text = f"_{i}"
        
        runslurm_file_name = f"{run_folder_name}/slurm_files/run{slurm_instance_text}.slurm"
        executable_file_name = f"{run_folder_name}/slurm_files/run{slurm_instance_text}.sh"
        log_file_name = f"{run_folder_name}/slurm_files/log{slurm_instance_text}.slurm"

        # Script to run the file and save outputs in log
        code, args_replace = slurm.generate_slurm_executable(file_extension, run_folder_name, target_file_path, args, target_file=target_file, slurm_instance=i, ntpn=slurm_settings["ntasks-per-node"])
        # Save the script in the run_folder
        machine.write_file(executable_file_name, code, verbose=True)

        # Define job name
        job_name = f"{target}/{name}{slurm_instance_text}"

        # Add arguments to the slurm job name
        if len(args_replace) > 0:
            args_ = args_replace.replace(" ", "_")
            if len(args_) != 0 and args_[0] == "_":
                args_ = args_[1:]
            
            job_name = f"{job_name}_{args_}"
        
        # Generate the slurm settings script
        code = slurm.generate_code_for_slurm_script(run_folder_name, slurm_settings, runslurm_file_name, executable_file_name, log_file_name, job_name=job_name)

        # Write the slurm file
        machine.write_file(runslurm_file_name, code, verbose=True)

        # Run the slurm file
        machine.run_code(f"sbatch {runslurm_file_name}", verbose=True)

def get_script_name(run_folder_name, script_name):
    
    # Search in the run_folder for the script_name with * as a wildcard
    script_name_ = os.path.join(run_folder_name, script_name)
    script_names = glob.glob(script_name_)
    assert len(script_names) == 1, f"Found {len(script_names)} scripts matching {script_name} in {run_folder_name}."
    script_name_ = script_names[0]

    # Remove the run_folder_name from the script_name
    script_name = os.path.basename(script_name_)
    
    return script_name

def mode_run_file(folder_name, run_folder_name, source_file_path, local_project_dir, target_file_path, machine, pargs, interpreter_args=""):
    assert pargs.name is not None, "The container_name -n must be specified."

    #Syncs folders
    machine.sync_files()

    # Creates folder if it does not exist and checks if the caspsule already exists.
    code = f'''
    mkdir -p {folder_name}
    if [ -d "{run_folder_name}" ]
    then
        echo "exists"
    else
        mkdir -p {run_folder_name}
        echo "ok"
    fi
    '''
    out = machine.run_code(code)
    assert len(out) == 1, str(out)
    out = out[0]

    if out == "ok":
        pass

    elif out == "exists":
        if not pargs.yes:
            c = input(f"The capsule {run_folder_name} already exists. This will overwrite {run_folder_name}. Do you whish to continue y/n? ")
            if c == "y" or c == "Y":
                pass
            else:
                quit()

    else:
        raise Exception(f"Unexpected value {out}.")

    # Copy the local copy of pargs.target to the run_folder
    machine.push(source_file_path, target_file_path, directory=False, verbose=True)

    # Run the file and save outputs in log, save PID in the file pid.
    mode_rerun_file(run_folder_name=run_folder_name, local_project_dir=local_project_dir, machine=machine, pargs=pargs, rerun=False)

def mode_run_folder(folder_name, run_folder_name, source_file_path, local_project_dir, machine, pargs, interpreter_args=""):
    assert pargs.name is not None, "The container_name -n must be specified."

    # Syncs folders
    machine.sync_files()

    # Creates folder if it does not exist and checks if the caspsule already exists.
    code = f'''
    mkdir -p {folder_name}
    if [ -d "{run_folder_name}" ]
    then
        echo "exists"
    else
        mkdir -p {run_folder_name}
        echo "ok"
    fi
    '''
    out = machine.run_code(code)
    assert len(out) == 1, str(out)
    out = out[0]

    if out == "ok":
        pass

    elif out == "exists":
        if not pargs.yes:
            c = input(f"The capsule {run_folder_name} already exists. This will overwrite {run_folder_name}. Do you whish to continue y/n? ")
            if c == "y" or c == "Y":
                pass
            else:
                quit()
    else:
        raise Exception(f"Unexpected value {out}.")

    # Copy the local version of pargs.target to the run_folder
    machine.push(source_file_path, run_folder_name + "/", directory=True, copy_full_dir=False, verbose=True)

    # Patch settings with all .encap.conf files
    settings.load_encap_config_files_recursive(os.path.join(os.getcwd(), run_folder_name))

    # Infer the proper script_name
    if "script_name" in settings.config:
        script_name = settings.config["script_name"]
    else:
        # Defaul script name is run.*
        script_name = "run.*"
    
    script_name = get_script_name(run_folder_name, script_name)

    settings.config["script_name"] = script_name
    settings.args_config["script_name"] = script_name

    # Run the file and save outputs in log, save PID in the file pid.
    mode_rerun_file(run_folder_name=run_folder_name,
                    local_project_dir=local_project_dir, machine=machine,
                    pargs=pargs, rerun=False)
    

def mode_rerun_file(run_folder_name, local_project_dir, machine, pargs, rerun=True, interpreter_args=""):
    assert pargs.name is not None, "The container_name -n must be specified."

    # Check if the capsule in run_folder_name exists
    assert os.path.isdir(run_folder_name), f"The capsule {run_folder_name} does not exist."


    # Patch settings with all .encap.conf files
    settings.load_encap_config_files_recursive(os.path.join(os.getcwd(), run_folder_name))

    # If any git-tracking is enabled, then we need to save in the config
    if "git-track" in settings.config:
        settings.config["git-track"] = get_commit_hashes(settings.config["git-track"])
        
    # Save the settings
    settings.write_config_file(os.path.join(run_folder_name, ".encap_history.conf"), settings.config,
                               comment="This file is automatically generated by encap. Effective encap configuration file from last run that has no effect on future runs.")
    
    pid = None

    # Read settings
    if "args" in settings.config:
        args = settings.config["args"]
    else:
        args = ""
    
    if "script_name" in settings.config:
        target_file = settings.config["script_name"]
    else:
        # Infer the proper script_name, the default is run.* (This can only happen in folder mode)
        target_file = get_script_name(run_folder_name, "run.*")
        settings.config["script_name"] = target_file
        settings.args_config["script_name"] = target_file
    
    target_file_path = os.path.join(run_folder_name, target_file)
    _, file_extension = filename_and_file_extension(target_file_path)

    
    

    # If .encap.conf file exists in the run_folder, load it, merge it with the comannd line arguments and save it
    if os.path.exists(os.path.join(run_folder_name, ".encap.conf")):
        run_folder_config = settings.read_config_file(os.path.join(run_folder_name, ".encap.conf"))

        run_folder_config = settings.merge_dicts(run_folder_config, settings.args_config)
    else:
        run_folder_config = settings.args_config
    
    settings.write_config_file(os.path.join(run_folder_name, ".encap.conf"), run_folder_config,
                               comment="This file is automatically generated by encap. This file will patch the global configuration file if the capsule is rerun.")

    if rerun:
        machine.sync_files()
        machine.push(target_file_path, target_file_path, directory=False, verbose=True) # TODO: The entire folder should be pushed, not just the file.
    
    # Are we using slurm?
    if not settings.using_slurm:
        if "i" in settings.config:
            number_of_instances = settings.config["i"]
        else:
            number_of_instances = 1
        
        pid = run(machine, file_extension, args, run_folder_name=run_folder_name, target_file=target_file, target_file_path=target_file_path, number_of_instances=number_of_instances)
    else:

        # Load the slurm settings from the loaded config file
        slurm_settings = slurm.read_slurm_settings_from_encapconfig(pargs.vm, local_project_dir)
        
        # Run the SLURM job with the slurm config file
        run_slurm(machine, file_extension, pargs.target, args, run_folder_name=run_folder_name, target_file=target_file, target_file_path=target_file_path, slurm_settings=slurm_settings, name=pargs.name)

    machine.pull(run_folder_name, run_folder_name, directory=True)

    # Record active process
    record_process(pargs.vm, pargs.target, pargs.name)
    tail_pull(machine, run_folder_name, pid)
    remove_process_from_database(pargs.target, pargs.name)


def parse_arguments():
    import argparse
    from argparse import ArgumentParser
    import textwrap

    parser = ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("mode", help=textwrap.dedent("""The mode of the program. Either run, rerun, tail or kill.
    run: Copies the target file into the capsule and runs it.
    rerun: Reruns the target file in the capsule without copying.
    tail: Tails the log file of the capsule.
    kill: Kills the running capsule. (currently not working)

    """))

    parser.add_argument("target", help="Name of the file to run.")
    parser.add_argument("-n", "--name", dest="name", help="Container name.", default=None)
    parser.add_argument("-args", "--args", dest="args", help="Arguments passed to the programm.", default=None)
    parser.add_argument("-vm", "--vm_name", dest="vm", help="Name of the VM.", default=None)
    parser.add_argument("-sn", "--script_name", dest="script_name", help="In case it is run on a folder this specifies the file that should be run. The default behaviour is to search for a file run.*.", default=None)
    parser.add_argument("-i", "--number_of_instances", dest="i", help="Number of instances to start in parallel. For each instance an enviromental variable ENCAP_PROCID=<instance_number> will be set. You can also pass a list or any python expression as a string. If you pass a list it will run the instances in that list. Example: -sl_i [0, 2, 3] or range(5, 20). Currently not compatible with slurm.", default=1, type=eval)

    # Slurm arguments
    parser.add_argument("-sl", "--slurm", action="store_true", dest="slurm", help="Run the job on slurm. If any slurm option is used this is True by default.", default=False)
    parser.add_argument("-sl_nodes", "--slurm_nodes", dest="sl_nodes", help="Number of nodes to start in slurm. - nodes", default=None, type=int)
    parser.add_argument("-sl_ntpn", "--slurm_ntasks-per-node", dest="sl_ntpn", help="Number of tasks per node to start in slurm. - ntasks-per-node", default=None, type=int)
    parser.add_argument("-sl_time", "--slurm_time", dest="sl_time", help="Time to run the job in slurm. - time", default=None)
    parser.add_argument("-sl_partition", "--slurm_partition", dest="sl_partition", help="Partition to run the job in slurm.", default=None)
    parser.add_argument("-sl_account", "--slurm_account", dest="sl_account", help="Account to run the job in slurm.", default=None)
    parser.add_argument("-sl_cpus", "--slurm_cpus-per-task", dest="sl_cpus", help="Number of cpus to run the job in slurm. - cpus-per-task", default=None, type=int)
    parser.add_argument("-sl_i", "--slurm_instances", dest="sl_i", help="Number of seperate slurm instances to start. If you use {i} in args it will be replaced by the index number of the slurm instance. Also for each instance an enviromental variable ENCAP_SLURM_INSTANCE=<instance_number> will be set. If you pass a list it will run the instances in that list. Example: -sl_i [0, 2, 3] or range(5, 20)", default=None, type=eval)
    
    # Other arguments
    parser.add_argument("-y", "--yes",
                        action="store_true", dest="yes", default=False,
                        help="All promts will be answerd with yes.")

    parser.add_argument("-d", "--debug",
                        action="store_true", dest="debug", default=False,
                        help="All commands will be printed.")

    parser.add_argument("-dr", "--dryrun",
                        action="store_true", dest="dryrun", default=False,
                        help="No command will be executed. Also implies debug.")

    pargs = parser.parse_args()

    # Read the data in
    if pargs.debug:
        settings.debug = True
    if pargs.dryrun:
        settings.dryrun = True
    
    settings.read_terminal_arguments(pargs) 
    return pargs

def main():

    pargs = parse_arguments()

    local_project_dir = os.getcwd()
    source_file_path = pargs.target
    localmachine = LocalMachine(local_project_dir)

    if pargs.vm is not None:
        machine = get_machine(pargs.vm, local_project_dir=local_project_dir)
    else:
        machine = localmachine
    
    # Check if it will run in folder mode or file mode
    if os.path.isdir(source_file_path):
        if source_file_path[-1] == "/":
            source_file_path = source_file_path[:-1]
        
        root_path, folder_name = extract_folder_name(source_file_path)

        run_folder_name = os.path.join(root_path, "0encap_folder", folder_name, pargs.name)

        is_file = False

    elif os.path.isfile(source_file_path):
        folder_name, file_extension = filename_and_file_extension(source_file_path)

        # Get the file name
        script_name = os.path.basename(source_file_path)

        run_folder_name = os.path.join(folder_name, pargs.name)
        settings.config["script_name"] = script_name
        target_file_path = os.path.join(run_folder_name, script_name)
        is_file = True


    else:
        assert False, f"{source_file_path} is neither a directory nor a file."
    

    if pargs.mode == "run":
        if is_file:
            mode_run_file(folder_name=folder_name, run_folder_name=run_folder_name,
                          source_file_path=source_file_path, local_project_dir=local_project_dir, target_file_path=target_file_path,
                          machine=machine, pargs=pargs)
        else:
            mode_run_folder(folder_name=folder_name, run_folder_name=run_folder_name,
                            source_file_path=source_file_path, local_project_dir=local_project_dir,
                            machine=machine, pargs=pargs)
        
    elif pargs.mode == "rerun":
        mode_rerun_file(run_folder_name=run_folder_name,
                        local_project_dir=local_project_dir,
                        machine=machine, pargs=pargs)
        
        
    elif pargs.mode == "tail":
        code = f"cat {run_folder_name}/pid"
        out = machine.run_code(code, verbose=True, output=True)
        print(machine.sync)
        assert len(out) == 1, out

        if out[0].isdigit():
            pid = out[0]
            print(pid)

            machine.pull(run_folder_name, run_folder_name, directory=True)

            tail_pull(machine, run_folder_name, pid)
            remove_process_from_database(pargs.target, pargs.name)

        elif  out[0][:4] == "cat:":
                machine.pull(run_folder_name, run_folder_name, directory=True)

                machine.run_code(f"cat {run_folder_name}/log", verbose=True, output=True)

    elif pargs.mode == "kill":
        # checks if folder exists, if yes take the pid and kill it.
        print(run_folder_name)
        code = f"""
        if [ -f {run_folder_name}/pid ]
        then
            cat {run_folder_name}/pid
        else
            echo "NoFolder"
        fi
        """
        pid = machine.run_code(code, verbose=False, output=True)[0]
        assert not pid == "NoFolder", "The PID file was not found."
        code = f"""
        kill {pid}
        rm {run_folder_name}/pid
        """

        machine.run_code(code, verbose=True, output=True)
        print("Killed process:", pid)
        print("Currently killing is not supported.")

    elif pargs.mode == "pull":
        assert pargs.name is not None, "The container_name -n must be specified."
        machine.pull(run_folder_name, run_folder_name, directory=True, verbose=True)

    elif pargs.mode == "push":
        assert pargs.name is not None, "The container_name -n must be specified."
        machine.push(run_folder_name, run_folder_name, directory=True, verbose=True)

    elif pargs.mode == "pkill":
        machine.run_code(f"pkill -f '{pargs.target}' -u {machine.username}", output=True, verbose=True)

    else:
        raise ValueError(f"The mode '{pargs.mode}' is not available.")


if __name__ == "__main__":
    main()